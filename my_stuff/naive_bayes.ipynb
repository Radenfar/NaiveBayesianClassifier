{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random # Random is the ONLY module I am allowing myself to use for this challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2. Simple Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, id: int, class_: str | None, abstract: str) -> None:\n",
    "        self.id: int = id\n",
    "        self.class_: str = class_\n",
    "        self.abstract: str = abstract\n",
    "\n",
    "    def get_type(self) -> str:\n",
    "        '''Returns: \"test\" | \"train\"'''\n",
    "        return \"train\" if self.class_ else \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3. DataModel Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModel:\n",
    "    def __init__(self, data_path: str, do_shuffle: bool = False) -> None:\n",
    "        '''\n",
    "        The DataModel class is a container for the data in the dataset.\n",
    "        This will be greatly helpful for the model to access the data in a structured way, and minimise risk of errors.\n",
    "        The data is stored in a list of Data objects, which contain the id, class, and abstract of the data as attributes.\n",
    "        The vocabulary size is also stored as an attribute, which is the number of unique words in the dataset.\n",
    "        This DataModel will be able to split data for validation sets and ensembles.\n",
    "        '''\n",
    "        self.data: list[Data] = []\n",
    "        self.vocabulary_size: int = 0\n",
    "        if not data_path or data_path.strip() == \"\":\n",
    "            self.data = []\n",
    "        else:\n",
    "            with open(data_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "            if do_shuffle:\n",
    "                random.shuffle(lines) # shouldn't be used for the test data just in case Kaggle expects the data in order\n",
    "            for line in lines[1:]:\n",
    "                line_split = line.strip().replace('\"', '').split(',')\n",
    "                if len(line_split) == 3:\n",
    "                    id, class_, abstract = line_split\n",
    "                    data = Data(id, class_, abstract)\n",
    "                    self.data.append(data)\n",
    "                else:\n",
    "                    id, abstract = line_split\n",
    "                    data = Data(id, None, abstract)\n",
    "                    self.data.append(data)\n",
    "        self.vocabulary_size = self.get_vocabulary_size()\n",
    "\n",
    "\n",
    "    def set_data(self, data: list[Data]) -> None:\n",
    "        '''Sets the data of this model to the given data and updates the vocab size.'''\n",
    "        self.data = data\n",
    "        self.vocabulary_size = self.get_vocabulary_size()\n",
    "\n",
    "\n",
    "    def get_vocabulary_size(self) -> int:\n",
    "        '''Returns the number of unique words in the dataset.'''\n",
    "        vocabulary = set()\n",
    "        for data in self.data:\n",
    "            words = data.abstract.split()\n",
    "            for word in words:\n",
    "                vocabulary.add(word)\n",
    "        self.vocabulary_size = len(vocabulary)\n",
    "        return self.vocabulary_size\n",
    "\n",
    "\n",
    "    def split_model(self, proportion: float) -> 'DataModel':\n",
    "        '''Splits this dataset into two data sets based on the proportion of the current data to be in the new split.'''\n",
    "        split_data = DataModel('')\n",
    "        split_index = int(len(self.data) * proportion)\n",
    "        split_data.set_data(self.data[:split_index])\n",
    "        self.set_data(self.data[split_index:])\n",
    "        return split_data\n",
    "    \n",
    "    \n",
    "    def eliminate_stop_words(self, stop_word_proportion) -> None:\n",
    "        '''\n",
    "        Stopwords include:\n",
    "        - Any word that is a single character\n",
    "        - Any word that is a number\n",
    "        - The top 10% of words that appear in all classes\n",
    "        '''\n",
    "        word_count = {}\n",
    "        num_eliminated = 0\n",
    "        for data in self.data:\n",
    "            words = data.abstract.split()\n",
    "            new_data = []\n",
    "            for word in words:\n",
    "                if len(word) > 1 and not word.isdigit():\n",
    "                    if word in word_count:\n",
    "                        word_count[word] += 1\n",
    "                    else:\n",
    "                        word_count[word] = 1\n",
    "                    new_data.append(word)\n",
    "                else:\n",
    "                    num_eliminated += 1\n",
    "            data.abstract = ' '.join(new_data)\n",
    "        stop_words = set()\n",
    "        num_words_to_eliminate = int(len(word_count) * stop_word_proportion)\n",
    "        for _ in range(num_words_to_eliminate):\n",
    "            max_word = max(word_count, key=word_count.get)\n",
    "            stop_words.add(max_word)\n",
    "            del word_count[max_word]\n",
    "            num_eliminated += 1\n",
    "        for data in self.data:\n",
    "            words = data.abstract.split()\n",
    "            new_data = []\n",
    "            for word in words:\n",
    "                if word not in stop_words:\n",
    "                    new_data.append(word)\n",
    "            data.abstract = ' '.join(new_data)\n",
    "        self.vocabulary_size = self.get_vocabulary_size()\n",
    "        print(f'Eliminated {num_eliminated} words. Including the {len(stop_words)} most common and {num_eliminated - len(stop_words)} single char / number words.')\n",
    "\n",
    "    \n",
    "    def bootstrap_sample(self, proportion, num_models) -> list['DataModel']:\n",
    "        '''Returns a list of num_models DataModels, each with a random sample of the data with proportion of the original data.'''\n",
    "        num_per_model = int(len(self.data) * proportion)\n",
    "        models = []\n",
    "        for _ in range(num_models):\n",
    "            new_data = []\n",
    "            for _ in range(num_per_model):\n",
    "                new_data.append(random.choice(self.data))\n",
    "            new_model = DataModel('')\n",
    "            new_model.set_data(new_data)\n",
    "            models.append(new_model)\n",
    "        return models        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4. Standard Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardNaiveBayes:\n",
    "    def __init__(self) -> None:\n",
    "        ''''\n",
    "        This is the standard Naive Bayes classifier. \n",
    "        It uses the training data to calculate the probabilities of each word in each class and then uses these probabilities to classify the test data.\n",
    "        The standard Naive Bayes has absolutely no added features or optimizations but still managed to get a 0.80 accuracy on the test data.\n",
    "        '''\n",
    "        self.training_data: DataModel = DataModel(\n",
    "            data_path=r\"data\\trg.csv\",\n",
    "            do_shuffle=False # this counts as data pre-processing and won't be used for the standard model\n",
    "        )\n",
    "        self.testing_data: DataModel = DataModel(\n",
    "            data_path=r\"data\\tst.csv\",\n",
    "            do_shuffle=False # ditto above\n",
    "        )\n",
    "        self.classes = [c for c in set([data.class_ for data in self.training_data.data])]\n",
    "        self.class_counts = self.get_class_counts()\n",
    "        self.class_probabilities = [count / len(self.training_data.data) for count in self.class_counts]\n",
    "        self.word_counts = self.get_word_counts()\n",
    "\n",
    "\n",
    "    def run_test_data(self, fileout: str) -> None:\n",
    "        with open(fileout, 'w') as f:\n",
    "            f.write(\"id,class\\n\")\n",
    "            for data in self.testing_data.data:\n",
    "                f.write(f\"{data.id},{self.classify_abstract(data.abstract)}\\n\")\n",
    "\n",
    "\n",
    "    def get_word_probability(self, word: str, class_index: int) -> float:\n",
    "        '''\n",
    "        p(class|word) = p(word|class) * p(class) / p(word)\n",
    "        '''\n",
    "        word_count = self.word_counts[class_index].get(word, 0)\n",
    "        class_count = self.class_counts[class_index]\n",
    "        word_in_class = word_count / class_count\n",
    "        class_probability = self.class_probabilities[class_index]\n",
    "        word_in_data = sum([self.word_counts[i].get(word, 0) for i in range(len(self.classes))]) / len(self.training_data.data)\n",
    "        if word_in_data == 0:\n",
    "            return 0\n",
    "        return word_in_class * class_probability / word_in_data\n",
    "\n",
    "\n",
    "    def classify_abstract(self, abstract: str) -> str:\n",
    "        '''Classifies the abstract into one of the classes. Returns the class. Uses the Naive Bayesian Classifier algorithm.'''\n",
    "        abstract_words = abstract.split()\n",
    "        class_probabilities = []\n",
    "        for i in range(len(self.classes)):\n",
    "            cur_class_probability = self.class_probabilities[i]\n",
    "            cur_class_probability = 1\n",
    "            for word in abstract_words:\n",
    "                cur_word_probability = self.get_word_probability(word, i)\n",
    "                if cur_word_probability == 0:\n",
    "                    continue\n",
    "                cur_class_probability *= cur_word_probability\n",
    "            class_probabilities.append(cur_class_probability)\n",
    "        max_class = self.classes[class_probabilities.index(max(class_probabilities))]\n",
    "        return max_class\n",
    "\n",
    "\n",
    "    def get_class_counts(self) -> list[int]:\n",
    "        '''Returns the count of each class in the training data. Match the order of the classes with the order of self.classes (classes[i] -> class_counts[i])'''\n",
    "        class_counts = [0] * len(self.classes)\n",
    "        for data in self.training_data.data:\n",
    "            class_counts[self.classes.index(data.class_)] += 1\n",
    "        return class_counts\n",
    "    \n",
    "\n",
    "    def get_word_counts(self) -> list[dict[str, int]]:\n",
    "        '''Returns the count of each word in each class. Match the order of the classes with the order of self.classes (classes[i] -> word_counts[i])'''\n",
    "        word_counts = [{} for _ in range(len(self.classes))]\n",
    "        for data in self.training_data.data:\n",
    "            for word in data.abstract.split():\n",
    "                if word not in word_counts[self.classes.index(data.class_)]:\n",
    "                    word_counts[self.classes.index(data.class_)][word] = 1\n",
    "                else:\n",
    "                    word_counts[self.classes.index(data.class_)][word] += 1\n",
    "        return word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5. Main Routine for the Standard Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.5585284280936456\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 10-fold repeated Cross-Validation for the Evaluation metric.\n",
    "    total_accuracy = 0\n",
    "    for _ in range(10):\n",
    "        accuracy = 0\n",
    "        model = StandardNaiveBayes()\n",
    "        validation_data = model.training_data.split_model(0.1)\n",
    "        for data in validation_data.data:\n",
    "            classification = model.classify_abstract(data.abstract)\n",
    "            if classification == data.class_:\n",
    "                accuracy += 1\n",
    "        total_accuracy += accuracy / len(validation_data.data)\n",
    "    print(f\"Average accuracy: {total_accuracy / 10}\")\n",
    "        \n",
    "    # Simple run of the model on test data\n",
    "    classifier = StandardNaiveBayes()\n",
    "    classifier.run_test_data(fileout=\"standard_output.csv\")\n",
    "    '''\n",
    "    -->    Accuracy Obtained: 0.800 (Kaggle)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedNaiveBayes:\n",
    "    def __init__(self, validation_data_split: float, alpha: float, stop_word_proportion: float, auto_load_data: bool = True) -> None:\n",
    "        '''\n",
    "        This model is an improvement on the standard naive bayes model. It includes the following improvements:\n",
    "        - Supporting validation data splits\n",
    "        - Dirichlet smoothing\n",
    "        - Stop word elimination\n",
    "        - Ability to combine words as features\n",
    "        - Supporting manual data loading for ensembles / superstructures of models        \n",
    "        '''\n",
    "        if auto_load_data:\n",
    "            self.training_data: DataModel = DataModel(\n",
    "                data_path=r\"data\\trg.csv\",\n",
    "                do_shuffle=True                         # Data stochasiticity parameter Figure 7.1\n",
    "            )\n",
    "            self.testing_data: DataModel = DataModel(\n",
    "                data_path=r\"data\\tst.csv\",\n",
    "                do_shuffle=False\n",
    "            )\n",
    "            self.training_data.eliminate_stop_words(stop_word_proportion) # stop word elimination parameter Figure 7.2\n",
    "            if validation_data_split > 0.0:        # validation data split parameter Figure 7.3\n",
    "                self.validation_data: DataModel = self.training_data.split_model(validation_data_split)\n",
    "            else:\n",
    "                self.validation_data = None\n",
    "            self.alpha = alpha\n",
    "            self.vocab_size = self.training_data.vocabulary_size\n",
    "            self.classes = [c for c in set([data.class_ for data in self.training_data.data])]\n",
    "            self.class_counts = self.get_class_counts()\n",
    "            self.class_probabilities = [count / len(self.training_data.data) for count in self.class_counts]\n",
    "            self.word_counts = self.get_word_counts()\n",
    "        else:\n",
    "            self.training_data = DataModel('')\n",
    "            self.testing_data = DataModel('')\n",
    "            self.validation_data = None\n",
    "            self.alpha = alpha                      # Dirichlet smoothing hyperparameter Figure 7.4\n",
    "            self.vocab_size = 0                     # Dirichlet smoothing hyperparameter Figure 7.5\n",
    "            self.classes = []\n",
    "            self.class_counts = []\n",
    "            self.class_probabilities = []\n",
    "            self.word_counts = []\n",
    "\n",
    "\n",
    "    def set_data(self, training_data: DataModel = None, testing_data: DataModel = None, validation_data: DataModel = None) -> None:\n",
    "        '''Method for manually setting the data. Needs to update several attributes of the model.'''\n",
    "        if training_data:\n",
    "            self.training_data.set_data(training_data.data)\n",
    "        if testing_data:\n",
    "            self.testing_data.set_data(testing_data.data)\n",
    "        if validation_data:\n",
    "            if self.validation_data:\n",
    "                self.validation_data.set_data(validation_data.data)\n",
    "            else:\n",
    "                self.validation_data = DataModel('')\n",
    "                self.validation_data.set_data(validation_data.data)\n",
    "        self.vocab_size = self.training_data.vocabulary_size\n",
    "        self.classes = [c for c in set([data.class_ for data in self.training_data.data])]\n",
    "        self.class_counts = self.get_class_counts()\n",
    "        self.class_probabilities = [count / len(self.training_data.data) for count in self.class_counts]\n",
    "        self.word_counts = self.get_word_counts()\n",
    "\n",
    "\n",
    "    def get_validation_accuracy(self, print_prediciton: bool = False) -> float:\n",
    "        '''Returns the accuracy of the model on the validation data.'''\n",
    "        if not self.validation_data:\n",
    "            print(f\"Model has no validation set.\")\n",
    "            return 0\n",
    "        correct = 0\n",
    "        for data in self.validation_data.data:\n",
    "            predicted_class = self.classify_abstract(data.abstract)\n",
    "            if print_prediciton:\n",
    "                print(f\"Predicted: {predicted_class} | Actual: {data.class_}\")\n",
    "            if predicted_class == data.class_:\n",
    "                correct += 1\n",
    "        return correct / len(self.validation_data.data)\n",
    "\n",
    "\n",
    "    def run_test_data(self, fileout: str, type_: str = \"test\") -> None:\n",
    "        '''Runs the model on either the testing or training data and writes the results to a file.'''\n",
    "        with open(fileout, 'w') as f:\n",
    "            f.write(\"id,class\\n\")\n",
    "            if type_ == \"test\":\n",
    "                for data in self.testing_data.data:\n",
    "                    f.write(f\"{data.id},{self.classify_abstract(data.abstract)}\\n\")\n",
    "            elif type_ == \"train\":\n",
    "                for data in self.training_data.data:\n",
    "                    f.write(f\"{data.id},{self.classify_abstract(data.abstract)}\\n\")\n",
    "            else:\n",
    "                raise ValueError(\"Invalid type_ argument. Must be 'test', 'validation', or 'train'.\")\n",
    "    \n",
    "    \n",
    "    def get_word_probability(self, word: str, class_index: int) -> float:\n",
    "        '''p(class|word) = p(word|class) * p(class) / p(word) ++ Dirichlet smoothing'''\n",
    "        word_count = self.word_counts[class_index].get(word, 0)\n",
    "        class_count = self.class_counts[class_index]\n",
    "        word_in_class = (word_count + self.alpha) / (class_count + self.alpha * self.vocab_size)\n",
    "        class_probability = self.class_probabilities[class_index]\n",
    "        word_in_data = (sum([self.word_counts[i].get(word, 0) for i in range(len(self.classes))]) + self.alpha) / (len(self.training_data.data) + self.alpha * self.vocab_size)\n",
    "        return word_in_class * class_probability / word_in_data\n",
    "\n",
    "\n",
    "    def classify_abstract(self, abstract: str) -> str:\n",
    "        '''Classifies the abstract into one of the classes. Returns the class. Uses the Naive Bayesian Classifier algorithm.'''\n",
    "        abstract_words = abstract.split()\n",
    "        class_probabilities = []\n",
    "        for i in range(len(self.classes)):\n",
    "            cur_class_probability = self.class_probabilities[i]\n",
    "            cur_class_probability = 1\n",
    "            for word in abstract_words:\n",
    "                cur_word_probability = self.get_word_probability(word, i)\n",
    "                if cur_word_probability == 0:\n",
    "                    continue\n",
    "                cur_class_probability *= cur_word_probability\n",
    "            class_probabilities.append(cur_class_probability)\n",
    "        max_class = self.classes[class_probabilities.index(max(class_probabilities))]\n",
    "        return max_class\n",
    "    \n",
    "\n",
    "\n",
    "    def get_class_counts(self) -> list[int]:\n",
    "        '''Returns the count of each class in the training data. Match the order of the classes with the order of self.classes (classes[i] -> class_counts[i])'''\n",
    "        class_counts = [0] * len(self.classes)\n",
    "        for data in self.training_data.data:\n",
    "            class_counts[self.classes.index(data.class_)] += 1\n",
    "        return class_counts\n",
    "    \n",
    "\n",
    "    def get_word_counts(self) -> list[dict[str, int]]:\n",
    "        '''Returns the count of each word in each class. Matches the order of the classes with the order of self.classes (classes[i] -> word_counts[i])'''\n",
    "        word_counts = [{} for _ in range(len(self.classes))]\n",
    "        for data in self.training_data.data:\n",
    "            words = data.abstract.split()\n",
    "            for word in words:\n",
    "                if word not in word_counts[self.classes.index(data.class_)]:\n",
    "                    word_counts[self.classes.index(data.class_)][word] = 1\n",
    "                else:\n",
    "                    word_counts[self.classes.index(data.class_)][word] += 1\n",
    "        return word_counts\n",
    "    \n",
    "\n",
    "    def save(self):\n",
    "        '''Saves the word counts to a txt file'''\n",
    "        with open(\"word_counts.txt\", 'w', encoding='utf-8') as f:\n",
    "            for i in range(len(self.classes)):\n",
    "                f.write('-'*100 + '\\n')\n",
    "                f.write(f\"Class: {self.classes[i]}\\n\")\n",
    "                f.write(f\"Class Count: {self.class_counts[i]}\\n\")\n",
    "                f.write(f\"Class Probability: {self.class_probabilities[i]}\\n\\n\")\n",
    "                for word, count in self.word_counts[i].items():\n",
    "                    f.write(f\"{word}: {count}\\n\")\n",
    "    \n",
    "\n",
    "    def tune_hyper_param(self, min_value: float, max_value: float, step: float, param: str) -> float: # Tuning Method Figure 7.6\n",
    "        '''Tunes the hyperparameter of the model and returns the best value.'''\n",
    "        if not self.validation_data:\n",
    "            print(\"Model has no validation set.\")\n",
    "            return 0\n",
    "        multiplier = 1\n",
    "        if isinstance(min_value, float):\n",
    "            multiplier = 10 ** len(str(min_value).split('.')[1])\n",
    "        min_value = int(min_value * multiplier)\n",
    "        max_value = int(max_value * multiplier)\n",
    "        step = int(step * multiplier)\n",
    "        best_value = min_value\n",
    "        best_accuracy = 0\n",
    "        for value in range(min_value, max_value, step):\n",
    "            setattr(self, param, value)\n",
    "            accuracy = self.get_validation_accuracy()\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_value = value\n",
    "        return best_value / multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminated 1847 words. Including the 95 most common and 1752 single char / number words.\n",
      "Validation Accuracy: 0.5267558528428093\n",
      "U\n"
     ]
    }
   ],
   "source": [
    "def create_divided_ensemble(num_models: int, alpha: float, stop_word_proportion: float, validation_proportion: float) -> list[ImprovedNaiveBayes]:\n",
    "    '''Creates num_models models and splits the training data into num_models parts. Each model is trained on a different part of the data.'''\n",
    "    ensemble: list[ImprovedNaiveBayes] = []\n",
    "    for j in range(num_models):\n",
    "        if j == 0:\n",
    "            auto_load = True\n",
    "            valid_prop = validation_proportion\n",
    "        else:\n",
    "            auto_load = False\n",
    "            valid_prop = 0.0\n",
    "        classifier = ImprovedNaiveBayes(\n",
    "            validation_data_split=valid_prop,\n",
    "            alpha=alpha,\n",
    "            stop_word_proportion=stop_word_proportion,\n",
    "            auto_load_data=auto_load\n",
    "        )\n",
    "        ensemble.append(classifier)\n",
    "    data_to_split = ensemble[0].training_data\n",
    "    split_size = len(data_to_split.data) // num_models\n",
    "    split_data = [data_to_split.data[i * split_size: (i + 1) * split_size] for i in range(num_models)]\n",
    "    for i in range(num_models):\n",
    "        new_datamodel = DataModel('')\n",
    "        new_datamodel.set_data(split_data[i])\n",
    "        if i == 0:\n",
    "            ensemble[i].set_data(training_data=new_datamodel)\n",
    "        else:\n",
    "            ensemble[i].set_data(training_data=new_datamodel, testing_data=ensemble[0].testing_data)\n",
    "    return ensemble\n",
    "\n",
    "\n",
    "def create_bootstrap_ensemble(num_models: int, alpha: float, stop_word_proportion: float, validation_proportion: float) -> list[ImprovedNaiveBayes]:\n",
    "    '''Creates num_models models and splits the training data into num_models parts. Each model is trained on a different part of the data.'''\n",
    "    ensemble: list[ImprovedNaiveBayes] = []\n",
    "    base_classifier = ImprovedNaiveBayes(\n",
    "        validation_data_split=validation_proportion,\n",
    "        alpha=alpha,\n",
    "        stop_word_proportion=stop_word_proportion\n",
    "    )\n",
    "    data_to_split = base_classifier.training_data\n",
    "    split_data = data_to_split.bootstrap_sample(1/num_models, num_models)\n",
    "    for i in range(num_models):\n",
    "        new_datamodel = DataModel('')\n",
    "        new_datamodel.set_data(split_data[i].data)\n",
    "        new_classifier = ImprovedNaiveBayes(\n",
    "            validation_data_split=0.0,\n",
    "            alpha=alpha,\n",
    "            stop_word_proportion=stop_word_proportion,\n",
    "            auto_load_data=False\n",
    "        )\n",
    "        new_classifier.set_data(training_data=new_datamodel, testing_data=base_classifier.testing_data)\n",
    "        ensemble.append(new_classifier)\n",
    "    return ensemble\n",
    "\n",
    "\n",
    "def test_ensemble(ensemble: list[ImprovedNaiveBayes], fileout: str, moderator_model = None) -> None:\n",
    "    '''Tests the ensemble on the testing data and writes the results to a file.'''\n",
    "    with open(fileout, 'w') as f:\n",
    "        f.write(\"id,class\\n\")\n",
    "        for data in ensemble[0].testing_data.data:\n",
    "            class_counts = {}\n",
    "            for classifier in ensemble:\n",
    "                predicted_class = classifier.classify_abstract(data.abstract)\n",
    "                if predicted_class in class_counts:\n",
    "                    class_counts[predicted_class] += 1\n",
    "                else:\n",
    "                    class_counts[predicted_class] = 1\n",
    "            print(f\"{data.id}: {class_counts}\")\n",
    "            if len(class_counts) >= 3 and moderator_model:\n",
    "                max_class = moderator_model.classify_abstract(data.abstract)\n",
    "                print(f\"Moderator Intervention: {max_class}\")\n",
    "            else:\n",
    "                max_class = max(class_counts, key=class_counts.get)\n",
    "            f.write(f\"{data.id},{max_class}\\n\")\n",
    "\n",
    "\n",
    "def validate_ensemble(ensemble: list[ImprovedNaiveBayes], validation_set: DataModel, moderator: ImprovedNaiveBayes | None = None) -> None:\n",
    "    '''Validates the ensemble on the validation data and prints the accuracy. Uses a moderator model if provided.'''\n",
    "    true_positives = 0\n",
    "    for data in validation_set.data:\n",
    "        class_counts = {}\n",
    "        for classifier in ensemble:\n",
    "            predicted_class = classifier.classify_abstract(data.abstract)\n",
    "            if predicted_class in class_counts:\n",
    "                class_counts[predicted_class] += 1\n",
    "            else:\n",
    "                class_counts[predicted_class] = 1\n",
    "        if len(class_counts) >= 3 and moderator:\n",
    "            max_class = moderator.classify_abstract(data.abstract)\n",
    "        else:\n",
    "            max_class = max(class_counts, key=class_counts.get)\n",
    "        if max_class == data.class_:\n",
    "            true_positives += 1\n",
    "    return true_positives / len(validation_set.data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ensemble: list[ImprovedNaiveBayes] = create_divided_ensemble(\n",
    "    #     num_models=5,\n",
    "    #     alpha=0.0001,\n",
    "    #     stop_word_proportion=0.02,\n",
    "    #     validation_proportion=0.1\n",
    "    # )\n",
    "    # ensemble[0].save()\n",
    "    # print(f\"Accuracy: {validate_ensemble(ensemble, ensemble[0].validation_data)}\")\n",
    "\n",
    "    classifier = ImprovedNaiveBayes(\n",
    "        validation_data_split=0.2,\n",
    "        alpha=0.01,\n",
    "        stop_word_proportion=0.01\n",
    "    )\n",
    "    print(f\"Validation Accuracy: {classifier.get_validation_accuracy()}\")\n",
    "    classifier.save()\n",
    "    print(classifier.classify_abstract(\n",
    "        \"trump trump trump\"\n",
    "    ))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
